{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install dagshub mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner=\"gchit21\",repo_name = \"ML\",mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Info Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data information gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"Alley\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"PoolQC\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"Fence\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"MiscFeature\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "df.drop('SalePrice',axis=1,inplace=True)\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(df,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation function code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for removing correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def corr_matrix(X, y, threshold=0.8):\n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    high_corr_pairs = []\n",
    "\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "    # To remove one feature from each highly correlated pair\n",
    "    features_to_drop = []\n",
    "    for feat1, feat2, _ in high_corr_pairs:\n",
    "        # Compare correlation with target and add the feature with lower correlation to target to the drop list\n",
    "        if abs(X[feat1].corr(y)) < abs(X[feat2].corr(y)):\n",
    "            features_to_drop.append(feat1)\n",
    "        else:\n",
    "            features_to_drop.append(feat2)\n",
    "\n",
    "    # Remove duplicates\n",
    "    features_to_drop = list(set(features_to_drop))\n",
    "\n",
    "    return features_to_drop,high_corr_pairs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        mode_val = df[col].mode()[0]\n",
    "        X_train.fillna({col:mode_val}, inplace=True)\n",
    "        X_test.fillna({col:mode_val},inplace=True)\n",
    "        \n",
    "    elif df[col].dtype in [\"int64\", \"float64\"]:\n",
    "        mean_val = df[col].mean()\n",
    "        X_train.fillna({col:mean_val}, inplace=True)\n",
    "        X_test.fillna({col:mean_val},inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping unnecessary columns (they have more than 95% Na or give no additional information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#dropping unnecessary columns from train set \n",
    "X_train.drop(['Alley','PoolQC'],axis=1,inplace=True)\n",
    "X_train.drop([\"Fence\",\"MiscFeature\"],axis=1,inplace=True)\n",
    "X_train.drop([\"MasVnrType\",\"MasVnrArea\"],axis=1,inplace=True)\n",
    "X_train.drop([\"FireplaceQu\",\"Fireplaces\"],axis=1,inplace=True)\n",
    "X_train.drop(\"Id\",axis=1,inplace=True)\n",
    "X_train.drop(\"MiscVal\",axis=1,inplace=True)\n",
    "X_train.drop(\"LowQualFinSF\",axis=1,inplace=True)\n",
    "X_train.drop(\"PoolArea\",axis=1,inplace=True)\n",
    "X_train.drop(\"3SsnPorch\",axis=1,inplace=True)\n",
    "\n",
    "# dropping unnecessary columns from test set(derived from train)\n",
    "X_test.drop(['Alley','PoolQC'],axis=1,inplace=True)\n",
    "X_test.drop([\"Fence\",\"MiscFeature\"],axis=1,inplace=True)\n",
    "X_test.drop([\"MasVnrType\",\"MasVnrArea\"],axis=1,inplace=True)\n",
    "X_test.drop([\"FireplaceQu\",\"Fireplaces\"],axis=1,inplace=True)\n",
    "X_test.drop(\"Id\",axis=1,inplace=True)\n",
    "X_test.drop(\"MiscVal\",axis=1,inplace=True)\n",
    "X_test.drop(\"LowQualFinSF\",axis=1,inplace=True)\n",
    "X_test.drop(\"PoolArea\",axis=1,inplace=True)\n",
    "X_test.drop(\"3SsnPorch\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get categorial columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get Categorial columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Cat_columns_less3 = [col for col in X_train.columns if df[col].dtype == 'object' and X_train[col].nunique()<=3]\n",
    "Cat_columns_more3 = [col for col in X_train.columns if df[col].dtype == 'object'and X_train[col].nunique()>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(Cat_columns_less3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(Cat_columns_more3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encoding and Woe encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from category_encoders.woe import WOEEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#make bins out of y so that woe is possible\n",
    "median = y_train.median()\n",
    "y_train_cp = (y_train>=median).astype(int).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOE encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "woe_encoder = WOEEncoder(cols=Cat_columns_more3)\n",
    "\n",
    "X_train[Cat_columns_more3] = woe_encoder.fit_transform(X_train[Cat_columns_more3],y_train_cp)\n",
    "X_test[Cat_columns_more3] = woe_encoder.transform(X_test[Cat_columns_more3])\n",
    "\n",
    "\n",
    "train_encoded = pd.get_dummies(X_train,columns=Cat_columns_less3,drop_first=True,dtype=int)\n",
    "test_encoded = pd.get_dummies(X_test,columns=Cat_columns_less3,drop_first=True,dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#dummies მეთოდმა შექმნა ეს სვეტი, 0-ებით სავსეა და უბრალოდ გადავაგდე, არაფრისმომცემია...\n",
    "train_encoded.drop(\"Utilities_NoSeWa\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_encoded.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features,high =corr_matrix(train_encoded,y_train,threshold=0.7)\n",
    "train_encoded_cp = train_encoded.drop(features,axis=1)\n",
    "test_encoded_cp = test_encoded.drop(features,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "scalerMinMax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(scaler.fit_transform(train_encoded_cp),columns=train_encoded_cp.columns)\n",
    "test_scaled=pd.DataFrame(scaler.transform(test_encoded_cp),columns=test_encoded_cp.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Mlflow logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Mlflow Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment_name = \"LinearRegression\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(run_name=\"Linear_Regression\"):\n",
    "\n",
    "    #model\n",
    "    linModel = LinearRegression()\n",
    "    \n",
    "    #RFE\n",
    "    rfeLin = RFE(estimator=linModel, n_features_to_select=15, step=2)\n",
    "    train_rfe=rfeLin.fit_transform(train_scaled, y_train)\n",
    "    test_rfe=rfeLin.transform(test_scaled)\n",
    "    rfe_selected_features = train_scaled.columns[rfeLin.support_].tolist()\n",
    "    \n",
    "    \n",
    "    #model fit\n",
    "    linModel.fit(train_rfe,y_train)\n",
    "    y_pred = linModel.predict(test_rfe)\n",
    "\n",
    "    #metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape=mean_absolute_percentage_error(y_test,y_pred)\n",
    "\n",
    "    #Mlflow logs\n",
    "    mlflow.log_param(\"model_type\", \"Linear_Regression\")\n",
    "    mlflow.log_param(\"scaling_method\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"correlation_threshold\",0.7)\n",
    "    mlflow.log_param(\"selected_features_n\",15)\n",
    "    mlflow.log_param(\"rfe_step\",2)\n",
    "    mlflow.log_param(\"selected_features\",rfe_selected_features)\n",
    "    mlflow.log_metric(\"R2\",r2)\n",
    "    mlflow.log_metric(\"RMSLE\",rmsle)\n",
    "    mlflow.log_metric(\"RMSE\",rmse)\n",
    "    mlflow.log_metric(\"MAPE\",mape)\n",
    "    #Mlflow log model\n",
    "    mlflow.sklearn.log_model(linModel, artifact_path=\"model\", registered_model_name=\"house_price_best_model\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas = [10, 5, 1]\n",
    "experiment_name = \"LinearRegression\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "for alpha in alphas:\n",
    "    with mlflow.start_run(run_name=f\"Lasso_alpha_{alpha}\"):\n",
    "        \n",
    "        #model\n",
    "        lasModel = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "        \n",
    "        #RFE\n",
    "        rfeLas = RFE(estimator=lasModel, n_features_to_select=15, step=1)\n",
    "        train_rfe=rfeLas.fit_transform(train_scaled, y_train)\n",
    "        test_rfe=rfeLas.transform(test_scaled)\n",
    "        rfe_selected_features = train_scaled.columns[rfeLas.support_].tolist()\n",
    "\n",
    "        #model fit and predict\n",
    "        lasModel.fit(train_rfe,y_train)\n",
    "        y_pred = lasModel.predict(test_rfe)\n",
    "\n",
    "        #metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmsle = np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred)))\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mape=mean_absolute_percentage_error(y_test,y_pred)\n",
    "\n",
    "        #Mlflow logs\n",
    "        mlflow.log_param(\"model_type\", \"Lasso\")\n",
    "        mlflow.log_param(\"max_iter\", 1000)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "        mlflow.log_param(\"scaling_method\", \"StandardScaler\")\n",
    "        mlflow.log_param(\"alpha\",alpha)\n",
    "        mlflow.log_param(\"correlation_threshold\",0.65)\n",
    "        mlflow.log_param(\"Selected_features_n\",15)\n",
    "        mlflow.log_param(\"Selected_features\",rfe_selected_features)\n",
    "        mlflow.log_metric(\"R2\",r2)\n",
    "        mlflow.log_metric(\"RMSLE\",rmsle)\n",
    "        mlflow.log_metric(\"RMSE\",rmse)\n",
    "        mlflow.log_metric(\"MAPE\",mape)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "alphas = [0.1, 0.05, 0.01]\n",
    "experiment_name = \"LinearRegression\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "for alpha in alphas:\n",
    "    with mlflow.start_run(run_name=f\"Ridge_alpha_{alpha}\"):\n",
    "\n",
    "        #model\n",
    "        ridgeModel = Ridge(alpha=alpha, random_state=42, max_iter=10000)\n",
    "        \n",
    "        #RFE\n",
    "        rfeRidge = RFE(estimator=ridgeModel, n_features_to_select=15, step=1)\n",
    "        train_rfe=rfeRidge.fit_transform(train_scaled, y_train)\n",
    "        test_rfe=rfeRidge.transform(test_scaled)\n",
    "        rfe_selected_features = train_scaled.columns[rfeRidge.support_].tolist()\n",
    "\n",
    "        #model fit and predict\n",
    "        ridgeModel.fit(train_rfe,y_train)\n",
    "        y_pred = ridgeModel.predict(test_rfe)\n",
    "\n",
    "        #metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmsle = np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred)))\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mape=mean_absolute_percentage_error(y_test,y_pred)\n",
    "        \n",
    "\n",
    "        #Mlflow Logs \n",
    "        mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "        mlflow.log_param(\"max_iter\", 1000)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "        mlflow.log_param(\"scaling_method\", \"StandardScaler\")\n",
    "        mlflow.log_param(\"alpha\",alpha)\n",
    "        mlflow.log_param(\"correlation_threshold\",0.65)\n",
    "        mlflow.log_param(\"selected_features_n\",15)\n",
    "        mlflow.log_param(\"Selected_features\",rfe_selected_features)\n",
    "        mlflow.log_metric(\"R2\",r2)\n",
    "        mlflow.log_metric(\"RMSLE\",rmsle)\n",
    "        mlflow.log_metric(\"RMSE\",rmse)\n",
    "        mlflow.log_metric(\"MAPE\",mape)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
