{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# This Python 3 environment comes with many helpful analytics libraries installed\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# For example, here's several helpful packages to load\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m \u001b[38;5;66;03m# linear algebra\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Input data files are available in the read-only \"../input/\" directory\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner=\"gchit21\",repo_name = \"ML\",mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpd\u001b[49m.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_columns\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      2\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_colwidth\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      3\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.expand_frame_repr\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Info Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\",sep=\",\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n",
    "test_dfcp = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "df.drop('SalePrice',axis=1,inplace=True)\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(df,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def corr_matrix(X, y, threshold=0.8):\n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    high_corr_pairs = []\n",
    "\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "    # To remove one feature from each highly correlated pair\n",
    "    features_to_drop = []\n",
    "    for feat1, feat2, _ in high_corr_pairs:\n",
    "        # Compare correlation with target and add the feature with lower correlation to target to the drop list\n",
    "        if abs(X[feat1].corr(y)) < abs(X[feat2].corr(y)):\n",
    "            features_to_drop.append(feat1)\n",
    "        else:\n",
    "            features_to_drop.append(feat2)\n",
    "\n",
    "    # Remove duplicates\n",
    "    features_to_drop = list(set(features_to_drop))\n",
    "\n",
    "    return features_to_drop,high_corr_pairs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        mode_val = df[col].mode()[0]\n",
    "        X_train.fillna({col:mode_val}, inplace=True)\n",
    "        X_test.fillna({col:mode_val},inplace=True)\n",
    "        test_dfcp.fillna({col:mode_val},inplace=True)\n",
    "    elif df[col].dtype in [\"int64\", \"float64\"]:\n",
    "        mean_val = df[col].mean()\n",
    "        X_train.fillna({col:mean_val}, inplace=True)\n",
    "        X_test.fillna({col:mean_val},inplace=True)\n",
    "        test_dfcp.fillna({col:mean_val},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#dropping unnecessary columns from train set \n",
    "X_train.drop(['Alley','PoolQC'],axis=1,inplace=True)\n",
    "X_train.drop([\"Fence\",\"MiscFeature\"],axis=1,inplace=True)\n",
    "X_train.drop([\"MasVnrType\",\"MasVnrArea\"],axis=1,inplace=True)\n",
    "X_train.drop([\"FireplaceQu\",\"Fireplaces\"],axis=1,inplace=True)\n",
    "X_train.drop(\"Id\",axis=1,inplace=True)\n",
    "X_train.drop(\"MiscVal\",axis=1,inplace=True)\n",
    "X_train.drop(\"LowQualFinSF\",axis=1,inplace=True)\n",
    "X_train.drop(\"PoolArea\",axis=1,inplace=True)\n",
    "X_train.drop(\"3SsnPorch\",axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#dropping unnecessary columns from test \n",
    "test_dfcp.drop([\"Alley\",\"PoolQC\",\"Fence\",\"MiscFeature\"],axis=1,inplace=True)\n",
    "test_dfcp.drop([\"MasVnrType\",\"MasVnrArea\",\"FireplaceQu\",\"Fireplaces\"],axis=1,inplace=True)\n",
    "test_dfcp.drop([\"Id\",\"MiscVal\",\"LowQualFinSF\",\"PoolArea\",\"3SsnPorch\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get categorial columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Cat_columns_less3 = [col for col in X_train.columns if df[col].dtype == 'object' and X_train[col].nunique()<=3]\n",
    "Cat_columns_more3 = [col for col in X_train.columns if df[col].dtype == 'object'and X_train[col].nunique()>3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encoding and Woe encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from category_encoders.woe import WOEEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#make bins out of y so that woe is possible\n",
    "median = y_train.median()\n",
    "y_train_cp = (y_train>=median).astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "woe_encoder = WOEEncoder(cols=Cat_columns_more3)\n",
    "\n",
    "X_train[Cat_columns_more3] = woe_encoder.fit_transform(X_train[Cat_columns_more3],y_train_cp)\n",
    "test_dfcp[Cat_columns_more3] = woe_encoder.transform(test_dfcp[Cat_columns_more3])\n",
    "\n",
    "train_encoded = pd.get_dummies(X_train,columns=Cat_columns_less3,drop_first=True,dtype=int)\n",
    "test_encoded = pd.get_dummies(X_test,columns=Cat_columns_less3,drop_first=True,dtype=int)\n",
    "test_df_encoded = pd.get_dummies(test_dfcp,columns=Cat_columns_less3,drop_first=True,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#duumies მეთოდმა შექმნა ეს სვეტი, 0-ებით სავსეა და უბრალოდ გადავაგდე, არაფრისმომცემია...\n",
    "train_encoded.drop(\"Utilities_NoSeWa\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features,high =corr_matrix(train_encoded,y_train,threshold=0.7)\n",
    "train_encoded_cp = train_encoded.drop(features,axis=1)\n",
    "test_df_encoded_cp = test_df_encoded.drop(features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(scaler.fit_transform(train_encoded_cp),columns=train_encoded_cp.columns)\n",
    "test_df_scaled = pd.DataFrame(scaler.transform(test_df_encoded_cp),columns=test_df_encoded_cp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Test.csv(the code above is for test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logged_model = 'runs:/b2299001c241408289c8823c8ecd9126/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "rfe = RFE(estimator=loaded_model, n_features_to_select=15, step=2)\n",
    "test_rfe = rfe.transform(test_df_scaled)\n",
    "# Predict on your data.\n",
    "Pred= loaded_model.predict(test_rfe)\n",
    "end_pred=pd.DataFrame(Pred,index=test_df.Id,columns=['SalePrice'])\n",
    "end_pred.to_csv('submission.csv',sep=',')\n",
    "end_pred.head()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
